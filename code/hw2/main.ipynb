{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CS 4395 NLP\n",
    "## Assignment 2\n",
    "### Samuel Anozie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Importing needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Printing the first 20 tokens from text1 in the nltk package\n",
    "\n",
    "The text object contains functions that help explore the tokens seen in text, and the tokens method houses all of the tokens available in the text by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied', 'by', 'a', 'Late', 'Consumptive', 'Usher', 'to', 'a', 'Grammar']\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import text1\n",
    "\n",
    "print(text1.tokens[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Using concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 455 matches:\n",
      " shall slay the dragon that is in the sea .\" -- ISAIAH \" And what thing soever \n",
      " S PLUTARCH ' S MORALS . \" The Indian Sea breedeth the most and the biggest fis\n",
      "cely had we proceeded two days on the sea , when about sunrise a great many Wha\n",
      "many Whales and other monsters of the sea , appeared . Among the former , one w\n",
      " waves on all sides , and beating the sea before him into a foam .\" -- TOOKE ' \n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"sea\", lines=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. Using count\n",
    "\n",
    "The count function in the API is simply a wrapper for Python’s own count function, except the API version specifically counts the frequency of a word in the token list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "433"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count('sea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count('pout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. Tokenizing raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['In',\n '2018',\n 'Apple',\n 'introduced',\n 'iPhone',\n 'X',\n 'and',\n 'with',\n 'it',\n 'the']"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = \"In 2018 Apple introduced iPhone X and with it the controversial “notch” area reserved for the front-facing camera system. Snap, Instagram, and BeReal have ensured that front-facing imaging is not going anywhere. It’s only growing. Essentially it was a dead area of the screen that had to be tolerated and accepted. If the usable phone screen was a continent, the notch was an annoying gulf that interrupted content on the phone. After sitting with the “bug” for 5 years, Apple has decided to what good designers often do: embrace constraints instead of tolerating them.\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(raw_text)\n",
    "tokens[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "6. Tokenizing sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['In 2018 Apple introduced iPhone X and with it the controversial “notch” area reserved for the front-facing camera system.',\n 'Snap, Instagram, and BeReal have ensured that front-facing imaging is not going anywhere.',\n 'It’s only growing.',\n 'Essentially it was a dead area of the screen that had to be tolerated and accepted.',\n 'If the usable phone screen was a continent, the notch was an annoying gulf that interrupted content on the phone.',\n 'After sitting with the “bug” for 5 years, Apple has decided to what good designers often do: embrace constraints instead of tolerating them.']"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "7. List comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', '2018', 'appl', 'introduc', 'iphon', 'x', 'and', 'with', 'it', 'the', 'controversi', '“', 'notch', '”', 'area', 'reserv', 'for', 'the', 'front-fac', 'camera', 'system', '.', 'snap', ',', 'instagram', ',', 'and', 'bereal', 'have', 'ensur', 'that', 'front-fac', 'imag', 'is', 'not', 'go', 'anywher', '.', 'it', '’', 's', 'onli', 'grow', '.', 'essenti', 'it', 'wa', 'a', 'dead', 'area', 'of', 'the', 'screen', 'that', 'had', 'to', 'be', 'toler', 'and', 'accept', '.', 'if', 'the', 'usabl', 'phone', 'screen', 'wa', 'a', 'contin', ',', 'the', 'notch', 'wa', 'an', 'annoy', 'gulf', 'that', 'interrupt', 'content', 'on', 'the', 'phone', '.', 'after', 'sit', 'with', 'the', '“', 'bug', '”', 'for', '5', 'year', ',', 'appl', 'ha', 'decid', 'to', 'what', 'good', 'design', 'often', 'do', ':', 'embrac', 'constraint', 'instead', 'of', 'toler', 'them', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(w) for w in tokens]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "8. Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', '2018', 'Apple', 'introduced', 'iPhone', 'X', 'and', 'with', 'it', 'the', 'controversial', '“', 'notch', '”', 'area', 'reserved', 'for', 'the', 'front-facing', 'camera', 'system', '.', 'Snap', ',', 'Instagram', ',', 'and', 'BeReal', 'have', 'ensured', 'that', 'front-facing', 'imaging', 'is', 'not', 'going', 'anywhere', '.', 'It', '’', 's', 'only', 'growing', '.', 'Essentially', 'it', 'wa', 'a', 'dead', 'area', 'of', 'the', 'screen', 'that', 'had', 'to', 'be', 'tolerated', 'and', 'accepted', '.', 'If', 'the', 'usable', 'phone', 'screen', 'wa', 'a', 'continent', ',', 'the', 'notch', 'wa', 'an', 'annoying', 'gulf', 'that', 'interrupted', 'content', 'on', 'the', 'phone', '.', 'After', 'sitting', 'with', 'the', '“', 'bug', '”', 'for', '5', 'year', ',', 'Apple', 'ha', 'decided', 'to', 'what', 'good', 'designer', 'often', 'do', ':', 'embrace', 'constraint', 'instead', 'of', 'tolerating', 'them', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "lemmatized = [wnl.lemmatize(w) for w in tokens]\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Differences in the stemmer and lemmatizer:\n",
    "\n",
    "in -> In\n",
    "\n",
    "appl -> Apple\n",
    "\n",
    "introduc -> introduced\n",
    "\n",
    "iphon -> iPhone\n",
    "\n",
    "x -> X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "9. Overall Comments\n",
    "\n",
    "NLTK is a very useful tool for processing text data. Personally, I would like to know if NLTK can help attach different sentiments to words as well, or generally testing the limitations of the framework.\n",
    "The code snippets in NLTK are very well documented, and are relatively easy to use as well. I'd like to use this framework to parse question data, since that is my primary focus when it comes to NLP. I could also see this being used for scraping websites, or validating / generating closed captions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}